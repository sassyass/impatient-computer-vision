{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/thesteve0/impatient-computer-vision/blob/main/2_classify_embed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# Classification and Embedding\n",
    "\n",
    "We are going to do our housekeep steps which will take a little while to run. While they are running we will go back to slides and I will introduce the topics.\n",
    "\n",
    "### Housekeeping\n",
    "Before we do anything else, we are need to change our machine time to one that has a GPU. Doing computer vision tasks with a CPU, except for some specific models, is extremely slow. One of the reasons we are using Colab is that you can get free access to a GPU for the workshop.\n",
    "\n",
    "Please:\n",
    "1. Go up to the top right of the browser\n",
    "2. Select \"Connect\"\n",
    "3. Then \"Change Runtime Type\"\n",
    "![change_runtime](assets/2_pick_GPU1.png)\n",
    "\n",
    "4. Pick T4 GPU\n",
    "5. Click Save\n",
    "![pick GPU](assets/2_pick_GPU2.png)\n",
    "\n",
    "6. When the run time connects it should look like this\n",
    "![running GPU](assets/2_pick_GPU3.png)\n",
    "\n",
    "\n",
    "Time to do our long running tasks\n",
    "1. Load the dependencies\n",
    "2. Map the drive\n",
    "2. Load the data"
   ],
   "id": "6ac74d2c4769e77a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install fiftyone==1.4.1 torch torchvision umap-learn\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import fiftyone as fo\n",
    "\n",
    "name = \"our-photos\"\n",
    "dir = \"/content/drive/MyDrive/impatient-cv/flickr-labeled\"\n",
    "\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir=dir,\n",
    "    dataset_type=fo.types.FiftyOneDataset,\n",
    "    name=name\n",
    ")\n",
    "\n",
    "print(dataset)"
   ],
   "id": "d62882049a2cb251"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Classification\n",
    "\n",
    "As we discussed in the slides, Classification is the computer vision task where you try to assign an image to single class out of a list of classes. We are going to use a classification model that is the foundation for many other models and is still quite powerful - ResNet. We are going to use the simplement version, ResNet18, because:\n",
    "\n",
    "1. It doesn't require much GPU resources\n",
    "2. It is fast to compute\n",
    "\n",
    "There are many variations to ResNet where a number is appended to the name. This number usually represents the number of layers in the neural network.\n",
    "\n",
    "### Training data\n",
    "\n",
    "While ResNet18 has a specific architecture, to use it for predictions, the model needs to be trained on data. There are many foundational data sets in computer vision but, a partciularly common one is [ImageNet](https://www.image-net.org/index.php). This dataset has 1k classes and millions of annotated images.\n",
    "\n",
    "Please open the list of the [imagenet classes](https://deeplearning.cms.waikato.ac.nz/user-guide/class-maps/IMAGENET/) in another browser tab. We will be referring to this later in the notebook\n",
    "\n",
    "FiftyOne has a [dataset zoo](https://docs.voxel51.com/dataset_zoo/datasets.html) where many important computer vision datasets have been converted into FiftyOne format and are easy to download and view.\n",
    "\n",
    "Let's go ahead and download and view a small subset of the ImageNet Data, the [ImageNet Sample Data](https://docs.voxel51.com/dataset_zoo/datasets.html#imagenet-sample)"
   ],
   "id": "10bb2367138ac9fd"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "1. import fiftyone.zoo as foz\n",
    "\n",
    "imagenet_samples = foz.load_zoo_dataset(\"imagenet-sample\")\n",
    "\n",
    "session = fo.launch_app(imagenet_samples, auto=False)\n",
    "\n",
    "session.url\n"
   ],
   "id": "f5b8e88ab46b2d09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### FiftyOne Model Zoo\n",
    "\n",
    "The computer vision platform we have been using, FiftyOne, also has a set of models already converted into a format that works with the rest of the FiftyOne platform. Typically, you would have to use library specific code, such as PyTorch, along with other code to specify the architecture to run a computer vision model. With FiftyOne, we can load the model in one line of code,  and then run it for classification (inference) with another line of code. Two lines of code and you are in business.\n",
    "\n",
    "#### ResNet18 in the model zoo\n",
    "\n",
    "We are going to load the PytTorch version of [ResNet18 model](https://docs.voxel51.com/model_zoo/models.html#resnet18-imagenet-torch) that was trained on ImageNet"
   ],
   "id": "5d53686ea50c84dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "resnet18_imagenet_model = foz.load_zoo_model(\"resnet18-imagenet-torch\")\n",
   "id": "35c7c114a8295159"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Predictions of our Photos\n",
    "\n",
    "We loaded our Flickr dataset and we have loaded our classification model, time to have it predict the classifications for our images."
   ],
   "id": "513b4af3b87017cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataset.apply_model(resnet18_imagenet_model, label_field=\"rn18_in_predictions\", num_workers=12, progress_bar=True)\n",
    "\n",
    "# Now let's look at the results\n",
    "session.dataset = dataset"
   ],
   "id": "a5b1a3f3e26848bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Deep dive on the horse\n",
    "\n",
    "I want us to dig is on one particular sample\n"
   ],
   "id": "357f29b0d104d977"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "horse_valley = dataset[\"6773012fa08cade6ec7e44f2\"]\n",
    "\n",
    "session.sample_id = horse_valley[\"id\"]"
   ],
   "id": "74c3795d61d77fc3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now let's see what the generated predictions tell us",
   "id": "d6fba8ef09ee497c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch.nn.functional as TF\n",
    "import torch\n",
    "\n",
    "model_classes = resnet18_imagenet_model.classes\n",
    "logits = torch.from_numpy(horse_valley[\"rn18_in_predictions\"][\"logits\"])\n",
    "\n",
    "print(\"There are \" + str(len(logits))+ \" logits\")\n",
    "\n",
    "print(\"\\nHere are all the logits\")\n",
    "print(str(logits[:25]))\n",
    "\n",
    "confidences = TF.softmax(logits, dim=0)\n",
    "print(\"\\nHere are all the confidence scores\")\n",
    "print(str(confidences[:25]))\n",
    "\n",
    "# Get top 5 values and their indices\n",
    "top_values, top_indices = torch.topk(confidences, k=5)\n",
    "\n",
    "print(\"Top 5 confidence values:\", top_values)\n",
    "print(\"Their indices:\", top_indices)\n",
    "\n",
    "print(\"\\nPredictions in descending confidence:\\n\")\n",
    "for idx, value in zip(top_indices.tolist(), top_values.tolist()):\n",
    "    print(\"Prediction: \" + model_classes[idx] + \" \\tConfidence: \" + str(value))"
   ],
   "id": "aff087513d6e0199"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Discussing the results\n",
    "\n",
    "1. What are some of the main things you noticed about the predictions?\n",
    "2. Were the predicted classes surprising to you? Were they useful for our problem?\n",
    "3. Take home bonus - What did changing the number of workers do?\n",
    "\n",
    "Here are the important ideas I wanted you to take away\n",
    "\n",
    "1. The model only can predict classes it was trained on\n",
    "2. The model will associate the most similar images of its training data to the current image and then give it that class\n"
   ],
   "id": "4c56f098f03ffad1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Another ResNet Model\n",
    "\n",
    "To demonstrate the importance of training data, we are going to run another ResNet18 model, except I trained this model on [Pokemon images](https://huggingface.co/datasets/TheSteve0/pokemon).\n",
    "\n",
    "I put the model weights file in our shared drive.\n",
    "\n",
    "To use this model we are going to:\n",
    "1. Load the model into pytorch\n",
    "2. Run the model against our Flickr images\n",
    "3. Associate the classification labels back to our FiftyOne dataset\n",
    "4. View the results"
   ],
   "id": "1934b525e27e92b8"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "pokemon_class_labels = {0: \"Abra\", 1: \"Aerodactyl\", 2: \"Alakazam\", 3: \"Alolan Sandslash\", 4: \"Arbok\", 5: \"Arcanine\", 6: \"Articuno\", 7: \"Beedrill\", 8: \"Bellsprout\", 9: \"Blastoise\", 10: \"Bulbasaur\", 11: \"Butterfree\", 12: \"Caterpie\", 13: \"Chansey\", 14: \"Charizard\", 15: \"Charmander\", 16: \"Charmeleon\", 17: \"Clefable\", 18: \"Clefairy\", 19: \"Cloyster\", 20: \"Cubone\", 21: \"Dewgong\", 22: \"Diglett\", 23: \"Ditto\", 24: \"Dodrio\", 25: \"Doduo\", 26: \"Dragonair\", 27: \"Dragonite\", 28: \"Dratini\", 29: \"Drowzee\", 30: \"Dugtrio\", 31: \"Eevee\", 32: \"Ekans\", 33: \"Electabuzz\", 34: \"Electrode\", 35: \"Exeggcute\", 36: \"Exeggutor\", 37: \"Farfetchd\", 38: \"Fearow\", 39: \"Flareon\", 40: \"Gastly\", 41: \"Gengar\", 42: \"Geodude\", 43: \"Gloom\", 44: \"Golbat\", 45: \"Goldeen\", 46: \"Golduck\", 47: \"Golem\", 48: \"Graveler\", 49: \"Grimer\", 50: \"Growlithe\", 51: \"Gyarados\", 52: \"Haunter\", 53: \"Hitmonchan\", 54: \"Hitmonlee\", 55: \"Horsea\", 56: \"Hypno\", 57: \"Ivysaur\", 58: \"Jigglypuff\", 59: \"Jolteon\", 60: \"Jynx\", 61: \"Kabuto\", 62: \"Kabutops\", 63: \"Kadabra\", 64: \"Kakuna\", 65: \"Kangaskhan\", 66: \"Kingler\", 67: \"Koffing\", 68: \"Krabby\", 69: \"Lapras\", 70: \"Lickitung\", 71: \"Machamp\", 72: \"Machoke\", 73: \"Machop\", 74: \"Magikarp\", 75: \"Magmar\", 76: \"Magnemite\", 77: \"Magneton\", 78: \"Mankey\", 79: \"Marowak\", 80: \"Meowth\", 81: \"Metapod\", 82: \"Mew\", 83: \"Mewtwo\", 84: \"Moltres\", 85: \"MrMime\", 86: \"Muk\", 87: \"Nidoking\", 88: \"Nidoqueen\", 89: \"Nidorina\", 90: \"Nidorino\", 91: \"Ninetales\", 92: \"Oddish\", 93: \"Omanyte\", 94: \"Omastar\", 95: \"Onix\", 96: \"Paras\", 97: \"Parasect\", 98: \"Persian\", 99: \"Pidgeot\", 100: \"Pidgeotto\", 101: \"Pidgey\", 102: \"Pikachu\", 103: \"Pinsir\", 104: \"Poliwag\", 105: \"Poliwhirl\", 106: \"Poliwrath\", 107: \"Wigglytuff\", 108: \"Zapdos\", 109: \"Zubat\"}\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms.v2 as T\n",
    "from PIL import Image\n",
    "import fiftyone as fo\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.amp as amp\n",
    "\n",
    "# Enable CUDA optimization\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load model using pickle\n",
    "with open('/content/drive/MyDrive/impatient-cv/pokemon-classification-model.pt', 'rb') as f:\n",
    "    state_dict = pickle.load(f)\n",
    "\n",
    "# Create a ResNet18 model with no pre-trained weights\n",
    "model = models.resnet18(weights=None)\n",
    "\n",
    "# Modify the final layer to match the trained model's 150 output classes\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 150)\n",
    "\n",
    "# Check if keys have the nested prefix and remove it\n",
    "if any(k.startswith('model.model.') for k in state_dict.keys()):\n",
    "    new_state_dict = {k.replace('model.model.', ''): v for k, v in state_dict.items()}\n",
    "    state_dict = new_state_dict\n",
    "elif any(k.startswith('model.') for k in state_dict.keys()):\n",
    "    new_state_dict = {k.replace('model.', ''): v for k, v in state_dict.items()}\n",
    "    state_dict = new_state_dict\n",
    "\n",
    "# Load the state dict into the model\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# pre-processing transforms we did for model training\n",
    "transform = T.Compose([\n",
    "    T.ToImage(),\n",
    "    T.RGB(),\n",
    "    T.ToDtype(torch.float32, scale=True),\n",
    "    T.Resize(224),\n",
    "    T.CenterCrop(224),\n",
    "])\n",
    "\n",
    "# Load your FiftyOne dataset is already done in the notebook\n",
    "\n",
    "# Optional: Define class mapping for Pokemon species (if available)\n",
    "# class_names = {0: \"Pikachu\", 1: \"Charizard\", ...}\n",
    "class_names = pokemon_class_labels  # Set to None if unavailable\n",
    "\n",
    "# Custom dataset for parallel loading\n",
    "class PokemonDataset(Dataset):\n",
    "    def __init__(self, sample_ids, filepaths, transform=None):\n",
    "        self.sample_ids = sample_ids\n",
    "        self.filepaths = filepaths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_id = self.sample_ids[idx]\n",
    "        filepath = self.filepaths[idx]\n",
    "\n",
    "        image = Image.open(filepath).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return sample_id, image\n",
    "\n",
    "# Extract sample IDs and filepaths\n",
    "sample_ids = dataset.values(\"id\")\n",
    "filepaths = dataset.values(\"filepath\")\n",
    "\n",
    "# Create dataset and dataloader for parallel processing\n",
    "pokemon_dataset = PokemonDataset(sample_ids, filepaths, transform)\n",
    "dataloader = DataLoader(\n",
    "    pokemon_dataset,\n",
    "    batch_size=64,  # Larger batch size for GPU efficiency\n",
    "    num_workers=2,  # Reduced worker count to avoid warnings\n",
    "    pin_memory=True  # Faster data transfer to GPU\n",
    ")\n",
    "\n",
    "# Prepare for mixed precision if supported\n",
    "scaler = amp.GradScaler(enabled=True)\n",
    "\n",
    "# Create a list to store FiftyOne Classification objects\n",
    "all_classifications = [None] * len(sample_ids)\n",
    "\n",
    "# Process in batches\n",
    "with torch.no_grad():\n",
    "    for batch_ids, images in tqdm(dataloader):\n",
    "        # Move images to device\n",
    "        images = images.to(device, non_blocking=True)\n",
    "\n",
    "        # Run inference with mixed precision\n",
    "        with amp.autocast('cuda', enabled=True):\n",
    "            outputs = model(images)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            confidences, predictions = torch.max(probs, dim=1)\n",
    "\n",
    "        # Get results from GPU\n",
    "        predictions = predictions.cpu().numpy()\n",
    "        confidences = confidences.cpu().numpy()\n",
    "\n",
    "        # Store results as FiftyOne Classification objects\n",
    "        for i, sample_id in enumerate(batch_ids):\n",
    "            # Find index in the original arrays\n",
    "            idx = sample_ids.index(sample_id)\n",
    "\n",
    "            pred_idx = int(predictions[i])\n",
    "            confidence = float(confidences[i])\n",
    "\n",
    "            # Get class name if mapping exists\n",
    "            if class_names is not None:\n",
    "                pred_label = class_names.get(pred_idx, f\"Unknown({pred_idx})\")\n",
    "            else:\n",
    "                # If no class names mapping, use stringified index as label\n",
    "                pred_label = str(pred_idx)\n",
    "\n",
    "            # Create a FiftyOne Classification object\n",
    "            classification = fo.Classification(\n",
    "                label=pred_label,\n",
    "                confidence=confidence\n",
    "            )\n",
    "\n",
    "            all_classifications[idx] = classification\n",
    "\n",
    "# Use set_values to update all samples with classification objects in a single batch operation\n",
    "dataset.set_values(\"pokemon_classification\", all_classifications)\n",
    "\n",
    "# Save dataset\n",
    "dataset.save()\n",
    "\n",
    "print(\"\\nFinished classifying\\n\\n\")\n",
    "\n",
    "session = fo.launch_app(dataset, auto=False)\n",
    "session.url"
   ],
   "id": "4d0c4709340ef662",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Wrap up\n",
    "\n",
    "And with that we are done with classification. In the next notebook, we are going to reuse these models to demonstrate the importance of data when doing embeddings"
   ],
   "id": "54766fccb120fb44"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
