{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/thesteve0/impatient-computer-vision/blob/main/2_classify_embed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# Classification and Embedding\n",
    "\n",
    "We are going to do our housekeep steps which will take a little while to run. While they are running we will go back to slides and I will introduce the topics.\n",
    "\n",
    "### Housekeeping\n",
    "Before we do anything else, we are need to change our machine time to one that has a GPU. Doing computer vision tasks with a CPU, except for some specific models, is extremely slow. One of the reasons we are using Colab is that you can get free access to a GPU for the workshop.\n",
    "\n",
    "Please:\n",
    "1. Go up to the top right of the browser\n",
    "2. Select \"Connect\"\n",
    "3. Then \"Change Runtime Type\"\n",
    "![change_runtime](assets/2_pick_GPU1.png)\n",
    "\n",
    "4. Pick T4 GPU\n",
    "5. Click Save\n",
    "![pick GPU](assets/2_pick_GPU2.png)\n",
    "\n",
    "6. When the run time connects it should look like this\n",
    "![running GPU](assets/2_pick_GPU3.png)\n",
    "\n",
    "\n",
    "Time to do our long running tasks\n",
    "1. Load the dependencies\n",
    "2. Map the drive\n",
    "2. Load the data"
   ],
   "id": "6ac74d2c4769e77a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install fiftyone==1.4.1 torch torchvision umap-learn\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import fiftyone as fo\n",
    "\n",
    "name = \"our-photos\"\n",
    "dir = \"/content/drive/MyDrive/impatient-cv/flickr-labeled\"\n",
    "\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir=dir,\n",
    "    dataset_type=fo.types.FiftyOneDataset,\n",
    "    name=name\n",
    ")\n",
    "\n",
    "print(dataset)"
   ],
   "id": "d62882049a2cb251"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Classification\n",
    "\n",
    "As we discussed in the slides, Classification is the computer vision task where you try to assign an image to single class out of a list of classes. We are going to use a classification model that is the foundation for many other models and is still quite powerful - ResNet. We are going to use the simplement version, ResNet18, because:\n",
    "\n",
    "1. It doesn't require much GPU resources\n",
    "2. It is fast to compute\n",
    "\n",
    "There are many variations to ResNet where a number is appended to the name. This number usually represents the number of layers in the neural network.\n",
    "\n",
    "### Training data\n",
    "\n",
    "While ResNet18 has a specific architecture, to use it for predictions, the model needs to be trained on data. There are many foundational data sets in computer vision but, a partciularly common one is [ImageNet](https://www.image-net.org/index.php). This dataset has 1k classes and millions of annotated images.\n",
    "\n",
    "Please open the list of the [imagenet classes](https://deeplearning.cms.waikato.ac.nz/user-guide/class-maps/IMAGENET/) in another browser tab. We will be referring to this later in the notebook\n",
    "\n",
    "FiftyOne has a [dataset zoo](https://docs.voxel51.com/dataset_zoo/datasets.html) where many important computer vision datasets have been converted into FiftyOne format and are easy to download and view.\n",
    "\n",
    "Let's go ahead and download and view a small subset of the ImageNet Data, the [ImageNet Sample Data](https://docs.voxel51.com/dataset_zoo/datasets.html#imagenet-sample)"
   ],
   "id": "10bb2367138ac9fd"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "1. import fiftyone.zoo as foz\n",
    "\n",
    "imagenet_samples = foz.load_zoo_dataset(\"imagenet-sample\")\n",
    "\n",
    "session = fo.launch_app(imagenet_samples, auto=False)\n",
    "\n",
    "session.url\n"
   ],
   "id": "f5b8e88ab46b2d09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### FiftyOne Model Zoo\n",
    "\n",
    "The computer vision platform we have been using, FiftyOne, also has a set of models already converted into a format that works with the rest of the FiftyOne platform. Typically, you would have to use library specific code, such as PyTorch, along with other code to specify the architecture to run a computer vision model. With FiftyOne, we can load the model in one line of code,  and then run it for classification (inference) with another line of code. Two lines of code and you are in business.\n",
    "\n",
    "#### ResNet18 in the model zoo\n",
    "\n",
    "We are going to load the PytTorch version of [ResNet18 model](https://docs.voxel51.com/model_zoo/models.html#resnet18-imagenet-torch) that was trained on ImageNet"
   ],
   "id": "5d53686ea50c84dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "resnet18_imagenet_model = foz.load_zoo_model(\"resnet18-imagenet-torch\")\n",
   "id": "35c7c114a8295159"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Predictions of our Photos\n",
    "\n",
    "We loaded our Flickr dataset and we have loaded our classification model, time to have it predict the classifications for our images."
   ],
   "id": "513b4af3b87017cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataset.apply_model(resnet18_imagenet_model, label_field=\"rn18_in_predictions\", num_workers=12, progress_bar=True)\n",
    "\n",
    "# Now let's look at the results\n",
    "session.dataset = dataset"
   ],
   "id": "a5b1a3f3e26848bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Deep dive on the horse\n",
    "\n",
    "I want us to dig is on one particular sample\n"
   ],
   "id": "357f29b0d104d977"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "horse_valley = dataset[\"6773012fa08cade6ec7e44f2\"]\n",
    "\n",
    "session.sample_id = horse_valley[\"id\"]"
   ],
   "id": "74c3795d61d77fc3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now let's see what the generated predictions tell us",
   "id": "d6fba8ef09ee497c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch.nn.functional as TF\n",
    "import torch\n",
    "\n",
    "model_classes = resnet18_imagenet_model.classes\n",
    "logits = torch.from_numpy(horse_valley[\"rn18_in_predictions\"][\"logits\"])\n",
    "\n",
    "print(\"There are \" + str(len(logits))+ \" logits\")\n",
    "\n",
    "print(\"\\nHere are all the logits\")\n",
    "print(str(logits[:25]))\n",
    "\n",
    "confidences = TF.softmax(logits, dim=0)\n",
    "print(\"\\nHere are all the confidence scores\")\n",
    "print(str(confidences[:25]))\n",
    "\n",
    "# Get top 5 values and their indices\n",
    "top_values, top_indices = torch.topk(confidences, k=5)\n",
    "\n",
    "print(\"Top 5 confidence values:\", top_values)\n",
    "print(\"Their indices:\", top_indices)\n",
    "\n",
    "print(\"\\nPredictions in descending confidence:\\n\")\n",
    "for idx, value in zip(top_indices.tolist(), top_values.tolist()):\n",
    "    print(\"Prediction: \" + model_classes[idx] + \" \\tConfidence: \" + str(value))"
   ],
   "id": "aff087513d6e0199"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Discussing the results\n",
    "\n",
    "1. What are some of the main things you noticed about the predictions?\n",
    "2. Were the predicted classes surprising to you? Were they useful for our problem?\n",
    "3. Take home bonus - What did changing the number of workers do?\n",
    "\n",
    "Here are the important ideas I wanted you to take away\n",
    "\n",
    "1. The model only can predict classes it was trained on\n",
    "2. The model will associate the most similar images of its training data to the current image and then give it that class\n"
   ],
   "id": "4c56f098f03ffad1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Another ResNet Model\n",
    "\n",
    "To demonstrate the importance of training data, we are going to run another ResNet18 model, except I trained this model on [Pokemon images](https://huggingface.co/datasets/TheSteve0/pokemon).\n",
    "\n",
    "I put the model weights file in our shared drive.\n",
    "\n",
    "To use this model we are going to:\n",
    "1. Load the model into pytorch\n",
    "2. Run the model against our Flickr images\n",
    "3. Associate the classification labels back to our FiftyOne dataset\n",
    "4. View the results"
   ],
   "id": "1934b525e27e92b8"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = torch.load(\"pokemon-classification-model.pt\", map_location=device)\n",
    "model.eval()\n",
    "\n",
    "# Standard ResNet transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Optional: Define class mapping for Pokemon species (if available)\n",
    "# class_names = {0: \"Pikachu\", 1: \"Charizard\", ...}\n",
    "class_names = None  # Set to None if unavailable\n",
    "\n",
    "# Process images in batches\n",
    "batch_size = 16  # Adjust based on your available memory\n",
    "total_samples = len(dataset)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, total_samples, batch_size)):\n",
    "        batch_samples = dataset[i:min(i+batch_size, total_samples)]\n",
    "        batch_tensors = []\n",
    "        valid_indices = []\n",
    "\n",
    "        # Process each image\n",
    "        for j, sample in enumerate(batch_samples):\n",
    "            try:\n",
    "                image = Image.open(sample.filepath).convert('RGB')\n",
    "                tensor = transform(image)\n",
    "                batch_tensors.append(tensor)\n",
    "                valid_indices.append(j)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {sample.filepath}: {e}\")\n",
    "\n",
    "        if not batch_tensors:\n",
    "            continue\n",
    "\n",
    "        # Run inference\n",
    "        batch = torch.stack(batch_tensors).to(device)\n",
    "        outputs = model(batch)\n",
    "\n",
    "        # Get predictions\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        confidences, predictions = torch.max(probs, dim=1)\n",
    "\n",
    "        # Update samples\n",
    "        for j, idx in enumerate(valid_indices):\n",
    "            sample = batch_samples[idx]\n",
    "            pred_idx = predictions[j].item()\n",
    "            confidence = confidences[j].item()\n",
    "\n",
    "            # Get class name if mapping exists\n",
    "            if class_names is not None:\n",
    "                pred_label = class_names.get(pred_idx, f\"Unknown({pred_idx})\")\n",
    "            else:\n",
    "                pred_label = pred_idx\n",
    "\n",
    "            # Add prediction to sample with requested field name\n",
    "            sample[\"rn18_pm_predictions\"] = pred_label\n",
    "            sample[\"rn18_pm_confidence\"] = float(confidence)\n",
    "            sample.save()\n",
    "\n",
    "# Save dataset\n",
    "dataset.save()\n",
    "\n"
   ],
   "id": "4d0c4709340ef662",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ed27d763eb127aa2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
