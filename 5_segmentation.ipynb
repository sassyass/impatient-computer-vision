{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/thesteve0/impatient-computer-vision/blob/main/5_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# Segmentation\n",
    "\n",
    "With this new notebook we are going to take on Segmentation. This task tries to assign every pixel to a class.\n",
    "There are actually at least 3 types of segmentation\n",
    "\n",
    "1. Instance Segmentation - like object detection except there are no boxes. All the pixels the model thinks belong to the object are given a code equal to the class.\n",
    "2. Semantic Segmentation - all pixels are assigned to a class but there is no distinct object detection. For example, if one person is standing partially in front of another person, there will just be a big person blob that is the outline of the two people with no line in the middle\n",
    "3. Panoptic Segmentation - Every pixel is assigned to a class like in semantic segmentation but some classes get instance segmentation. In our \"Find the people in this picture example\", every pixel that doesn't belong to a person can be put into one class (\"background\") and then each individual person could be uniquely identified.\n",
    "\n",
    "\n",
    "Time to do housekeeping:"
   ],
   "id": "113b9ded3b9c606d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!pip install fiftyone==1.4.1 torch torchvision\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "name = \"our-photos\"\n",
    "dir = \"/content/drive/MyDrive/impatient-cv/flickr-labeled\"\n",
    "\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir=dir,\n",
    "    dataset_type=fo.types.FiftyOneDataset,\n",
    "    name=name\n",
    ")\n"
   ],
   "id": "cb9ec9489c2e3699"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Loading the model and looking at the results\n",
    "Let's go ahead and load one of the models from the zoo and then just apply it to our photos. This model was also trained on COCO and has a ResNet backbone. We'll go right ahead and load up the results in the app.\n",
    "\n",
    "By the way, this is not the full COCO dataset, it is only the 20 classes from PASCAL VOC Challenge\n",
    "\n",
    "http://host.robots.ox.ac.uk/pascal/VOC/voc2012/segexamples/index.html\n",
    "\n",
    "But the hint was here:\n",
    "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.segmentation.deeplabv3_resnet101.html#torchvision.models.segmentation.DeepLabV3_ResNet101_Weights\n",
    "\n",
    "Note, while this may look like instance segmentation, it is actually semantic segmentation. The model only produces masks over classes it recognizes, everything else gets a zero - which you can think of as \"other\"."
   ],
   "id": "7baad1797585afed"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "model = foz.load_zoo_model(\"deeplabv3-resnet101-coco-torch\")\n",
    "\n",
    "dataset.apply_model(\n",
    "    model,\n",
    "    label_field=\"segmentations\",\n",
    "    progres=True,\n",
    "    num_workers=2,\n",
    "    batch=64\n",
    ")\n",
    "\n",
    "session = fo.launch_app(dataset, auto=False)\n",
    "session.url"
   ],
   "id": "98d3311858125631",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Wrap up\n",
    "\n",
    "Segmentation is actually quite a sophisticated modeling task. The models to run this are a bit more involved so we are not going to dig in to much deeper on this one. Sometime people will use segmentation as a way to \"crop\" out items they want to classify. For example, if we were trying to identify faces in images, we could first segment out all the human faces and subtract the background out. This would give a much cleaner image to try and classify.\n",
    "\n",
    "The next notebook will be a more specialized technique called Keypoint Detection, it will allow us to estimate human (or other animal) poses or action.\n",
    "\n",
    "[Keypoints](https://github.com/thesteve0/impatient-computer-vision/blob/main/6_keypoints.ipynb)"
   ],
   "id": "9a32b9b2dd8d7c71"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
